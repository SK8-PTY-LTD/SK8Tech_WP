[7A37B60CFEA845B4A9865F86048A7C5E]
post_date = "2017-03-16 00:21:00"
post_date_gmt = "2017-03-15 13:21:00"
post_content = "
  <p>Another day, another fun internet thing that uses neural networks for facial manipulation. This time it’s DeepWarp, a demo created by Yaroslav Ganin, Daniil Kononenko, Diana Sungatullina, and Victor Lempitsky, that uses deep architecture to move human eyeballs in a still image. </p>
<p>First spotted by <em>Prosthetic Knowledge</em>, DeepWarp is focused on realistic “gaze manipulation.” The authors of the demo acknowledge that similar projects already exist (like the app-neural-networks-ai-smile-image-manipulation\">smile-manipulator FaceApp</a>), but without such a singular, detailed focus. </p>
<p>The authors note that their findings in this study could be applied to solve real-world issues of eye movement, like for “gaze correction in video conferencing.” It could also be useful for “talking head” scenarios, when reliance on a teleprompter shifts a person’s line of sight away from the camera. </p>
<div><aside><q>Changing Keanu’s male gaze</q></aside></div>
<p>The demo is available to try here. All you need to do is choose an image (horizontal seems to work best) featuring a person facing forward. After you upload that image, you can pick one of four eye-movement options, including roll and cross. DeepWarp will spit out an mp4 file of the resulting googly-eyed person. I tried this using images of Keanu Reeves and several dogs, but the demo didn’t work with the dogs.</p>      <div>
        
<div data-cb-dfp-id=\"unit=mobile_article_body\" data-cb-ad-id=\"Mobile article body\">
  
</div>

      </div>

<p>“Our system is reasonably robust against different head poses and deals correctly with the situations where a person wears glasses,” the authors wrote <a href=\"<<[site-url]>>/wp-content/uploads/2017/03/deepwarp_eccv2016-1.pdf\">in their study</a>. “Most of the failure modes (e.g., corresponding to extremely tilted head poses or large redirection angles involving disocclusion of the different parts of an eye) are not inherent to the model <a href=\"<<[site-url]>>/tag/design/\" title=\"Design\">Design</a> and can be addressed by augmenting the training data with appropriate examples.”</p>
<p>The authors say they plan to work on making the demo work more quickly in the future.</p>
  <figure>
  <span data-original=\"https://cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\">
    
      <video autoplay muted loop playsinline src=\"https://cdn0.vox-cdn.com/thumbor/WkuqM8FsjW9Lx52KyUa0pEO55EY=/0x0:360x270/320x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\" data-cid=\"site/gifv-1489503337_8224_538\" data-cdata='{\"video_urls\":{\"320\":\"https://cdn0.vox-cdn.com/thumbor/WkuqM8FsjW9Lx52KyUa0pEO55EY=/0x0:360x270/320x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\",\"520\":\"https://cdn0.vox-cdn.com/thumbor/s5PnxkjzFEl-RmY_Xwhxeo2NmqU=/0x0:360x270/520x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\",\"720\":\"https://cdn0.vox-cdn.com/thumbor/HK_kxlIRZoy3Gyn8pOLxIAJFHJc=/0x0:360x270/720x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\",\"920\":\"https://cdn0.vox-cdn.com/thumbor/cfygANh4C2Wps2M5fBa6ZsdhAeY=/0x0:360x270/920x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\",\"1120\":\"https://cdn0.vox-cdn.com/thumbor/JpKk67Wwy6TSJVGaPqBYdJTQcL0=/0x0:360x270/1120x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\",\"1320\":\"https://cdn0.vox-cdn.com/thumbor/qLWEggMcky9Bbac60k3_ATN0fNY=/0x0:360x270/1320x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\",\"1520\":\"https://cdn0.vox-cdn.com/thumbor/iaH5EySC87OhItDM4lJJz10hsRc=/0x0:360x270/1520x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\",\"1720\":\"https://cdn0.vox-cdn.com/thumbor/h8xvkJJlTTRWsTjTQfE27FmM1rQ=/0x0:360x270/1720x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\",\"1920\":\"https://cdn0.vox-cdn.com/thumbor/rnKdcnG0WJRh69nKCb6jzT3DP2M=/0x0:360x270/1920x0/filters:focal(0x0:360x270):gifv():no_upscale()/cdn1.vox-cdn.com/uploads/chorus_asset/file/8134271/1l5zto.gif\"}}'>
  
</video>
    
  </span>
  
</figure>

"
post_title = "You can use this machine learning demo to roll Keanu Reeves’ (or anyone’s) eyes"
post_excerpt = "Another day, another fun internet thing that uses neural networks for facial manipulation. This time it’s DeepWarp, a demo created by Yaroslav Ganin, Daniil Kononenko, Diana Sungatullina, and Victor Lempitsky, that uses deep architecture to move human eyeballs in a still image."
post_status = "publish"
comment_status = "open"
ping_status = "open"
post_password = ""
post_name = "you-can-use-this-machine-learning-demo-to-roll-keanu-reeves-or-anyones-eyes-2"
to_ping = ""
pinged = ""
post_modified = "2017-03-16 00:21:00"
post_modified_gmt = "2017-03-15 13:21:00"
post_content_filtered = ""
guid = "https://sk8.tech/?p=2052"
menu_order = "0"
post_type = "post"
post_mime_type = ""
vp_post_author = "08A18EE9B54B47FF8FBFE760E0967111"
vp_post_parent = 0
vp_term_taxonomy[0] = "524774806B8B4F4FBF503D8446F9007A"
vp_term_taxonomy[1] = "844AE9C5F4C74AA7B40E26ABC984E229"
vp_term_taxonomy[2] = "452F7CF6DA7F4404A9C684BF4C0AD786"
vp_term_taxonomy[3] = "03630BF2792F46D1B76CAC4F64E264BE"
dpsp_networks_shares#5C20577621374EF888F357892BDA1EEF = <<<serialized>>> <array>
dpsp_networks_shares#5C20577621374EF888F357892BDA1EEF["google-plus"] = 0
dpsp_networks_shares#5C20577621374EF888F357892BDA1EEF["pinterest"] = 0
dpsp_networks_shares_total#A1657A03BD5B4963B8A8AC84E29F9B0D = "0"
dpsp_networks_shares_last_updated#59ED9D157BB44614B7B40D17260E8354 = "1490602761"
