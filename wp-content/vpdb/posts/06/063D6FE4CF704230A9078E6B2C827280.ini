[063D6FE4CF704230A9078E6B2C827280]
post_date = "2017-03-22 07:11:58"
post_date_gmt = "2017-03-21 20:11:58"
post_content = "<p>Saying that Facebook is not a <em>traditional</em> media company implies that it is <em>some kind</em> of media company. It&#8217;s not necessarily &#8220;taking responsibility,&#8221; but it&#8217;s progress. When originally reporting on Zuck&#8217;s subtle change of heart, Josh Constine got into the nitty-gritty on why this matters:</p><blockquote>
<p>Pure technology platforms receive greater immunity regarding the content they serve, both legally and in the public eye. This stems from the 1996 Communications Decency Act&#8217;s Section 230(c), or the Good Samaritan act, that states &#8220;No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.&#8221; Media companies are considered more directly responsible for their content.</p>
</blockquote><p><strong>January 6, 2017</strong></p><p>A new year, a new approach. Facebook rang in 2017 with a new hire &#8212; former television anchor and charter school advocate Campbell Brown joined the company to lead Facebook&#8217;s News Partnerships team.</p><p>Notice that Brown joined as head of News <em>Partnerships</em>. Notice how a high-profile broadcast anchor is leading a team that is working primarily on the digital distribution of news. No disrespect to Brown, but her appointment feels more like an appeasement to those who are calling for a public editor on Facebook, and instead are getting (at best) a liaison between the opaque Facebook News Feed and actual editors in actual newsrooms. At worst, critics are getting front-row tickets to see a prop in the theater of Facebook&#8217;s PR machine.</p><p>The company clarified that Brown would not be taking on an editorial role or setting content policy for the company.</p><p>No dip.</p><p><strong>January 11, 2017</strong></p><p>This is where Facebook really starts to add insult to injury.</p><p>The company unveiled &#8220;The Journalism Project,&#8221; which is a combination of a few great initiatives to combat fake news and good old-fashioned bribery.</p><p>Some pieces of the Journalism Project &#8212; plans to work more closely with local news; hackathons where Facebook&#8217;s engineers and news site developers can work together; promotion of news literacy; and helping with eyewitness media &#8212; are steps in the right direction, vague as they may be.</p><p>But the good is packaged in with business proposals, like digests of Instant Articles, free trials for subscription outlets, training for newsrooms on Facebook&#8217;s journalism tools and free <a href=\"<<[site-url]>>/services/seo-sem/\" title=\"Analytics\" target=\"_blank\">Analytics</a> tools for journalists to see which news stories are trending.</p><p>Let&#8217;s remember that Instant Articles are a big part of the problem, blurring the line between the content and the source of the content. Tools that expand Instant Articles or help paid news outlets offer free trials through Facebook only expand the practice of Instant Articles and grow the media&#8217;s dependency on Facebook for views.</p><p>Tools, like Signal, which help journalists see stories that are trending, sound attractive. But the popularity of a news story doesn&#8217;t necessarily correlate with whether or not it deserves to be covered. Writing for clicks is very different from writing to inform the public, which shows how deeply Facebook misunderstands the problem altogether.</p><p><strong>Mid-January to mid-February 2017</strong></p><p>In the month following the announcement of the Journalism Project, Facebook took action. The company rolled out anti-fake news features in Germany and partnered with Google to help combat fake news in the French election.</p><p>Facebook executives also went before the public and discussed the situation. At a panel at UC Berkeley, VP of News Feed Adam Mosseri outlined ways to mitigate the spread of fake news, including retroactively notifying a user when they&#8217;ve consumed or shared something that has been flagged. Head of partnerships Dan Rose appeared onstage at Code Media in early February and touted the new party line: Facebook is a &#8220;new type of platform… where people discover a lot of media content.&#8221;</p><p>He also said that &#8220;at the end of the day, if people want to share stories that have been flagged with their friends, that&#8217;s ultimately their prerogative.&#8221;</p><p>Essentially, more of the same &#8220;it&#8217;s not our fault&#8221; but &#8220;we&#8217;re definitely working on it.&#8221;</p><p><strong>February 16, 2017</strong></p><p>Just over three months after the election, Mark Zuckerberg took to Facebook to post a 5,700-word manifesto that was full of warm fuzzies, buzzwords (but not the unflattering ones) and very little substance or coherence.</p><p>Zuck&#8217;s diary didn&#8217;t go into much detail regarding the fake news problems on Facebook, but it did make an effort to defend the social network. Our own Taylor Hatmaker did a great job breaking it down:</p><blockquote>
<p>Zuckerberg suggests that providing a &#8220;range of perspectives&#8221; will combat fake news and sensational content over time, but this appears to naively assume users have some inherent drive to seek the truth. Most social science suggests that people pursue information that concerns their existing biases, time and time again. Facebook does not have a solution for how to incentivize users to behave otherwise.</p>
<p>Even if we&#8217;re friends with people like ourselves, Zuckerberg thinks that Facebook feeds display &#8220;more diverse content&#8221; than newspapers or broadcast news. That&#8217;s a big claim, one that seems to embrace Facebook&#8217;s identity as a media company, and it&#8217;s not backed up by anything at all.</p>
<p>Facebook explains that its approach &#8220;will focus less on banning misinformation, and more on surfacing additional perspectives and information.&#8221; For fear of backlash, Facebook will sit this one out, pretty much.</p>
<p>Zuckerberg thinks the real problem is polarization across not only <a href=\"<<[site-url]>>/services/content-marketing/\" title=\"Social Media\" target=\"_blank\">Social Media</a> but also &#8220;groups and communities, including companies, classrooms and juries,&#8221; which he clumsily dismisses as &#8220;usually unrelated to politics.&#8221; Basically, Facebook will reflect the systemic inequities found elsewhere in society and it shouldn&#8217;t really be expected to do otherwise.</p>
<p>Zuck &#8220;[wants] to emphasize that the vast majority of conversations on Facebook are social, not ideological.&#8221; By design, so are the vast majority of conversations Facebook has about Facebook. The company continues to be terrified of appearing politically or ideologically aligned.</p>
</blockquote>"
post_title = "Fake times"
post_excerpt = "Saying that Facebook is not a traditional media company implies that it is some kind of media company. It&#8217;s not necessarily &#8220;taking responsibility,&#8221; but it&#8217;s progress. When originally reporting on Zuck&#8217;s subtle change of heart, Josh Constine got into the nitty-gritty on why this matters:"
post_status = "future"
comment_status = "open"
ping_status = "open"
post_password = ""
post_name = "fake-times"
to_ping = ""
pinged = ""
post_modified = "2017-03-22 07:11:58"
post_modified_gmt = "2017-03-21 20:11:58"
post_content_filtered = ""
guid = "https://sk8.tech/?p=2811"
menu_order = "0"
post_type = "post"
post_mime_type = ""
vp_post_author = "08A18EE9B54B47FF8FBFE760E0967111"
vp_post_parent = 0
vp_term_taxonomy[0] = "524774806B8B4F4FBF503D8446F9007A"
vp_term_taxonomy[1] = "844AE9C5F4C74AA7B40E26ABC984E229"
vp_term_taxonomy[2] = "452F7CF6DA7F4404A9C684BF4C0AD786"
vp_term_taxonomy[3] = "B90448F852514509A34E143622129D91"
vp_term_taxonomy[4] = "03630BF2792F46D1B76CAC4F64E264BE"
